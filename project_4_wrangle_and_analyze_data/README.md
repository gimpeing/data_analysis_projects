# Project 4: Wrangle and Analyze Data

In this project, the goal is wrangle **WeRateDogs Twitter** data to create interesting and trustworthy analyses and visualizations. The Twitter archive data available in csv format is only contains very basic tweet information. Thus, I need to gather additional data, then assessing and cleaning it before analysing and come out with visalizations


## Contents:
### Part 1 :Data collection
1. **WeRateDogs** Twitter archive, `twitter_archive_enhanced.csv`
2. The tweet image predictions, i.e. what breed of dog is present in each tweet. Data store in `image_predictions.tsv`
3. Additional tweet's data, for example the `retweet count` and `favorite` ("like") count, using the `tweet ID` in the **WeRateDogs** Twitter archive, query the Twitter API for each tweet's JSON data using Python's **Tweepy** library and store each tweet's entire set of JSON data in a file, named `tweet_json.txt`.

### Part 2: Assess and Clean
After gathering each of the above pieces of data, assess them visually and programmatically for quality and tidiness issues. Detect and document at least eight (8) quality issues and two (2) tidiness issues.

### Part 3 : Analysis and Visualization
To analyze the data and come out with at least 3 insights and 1 visualization

## Conclusion:



```python

```
